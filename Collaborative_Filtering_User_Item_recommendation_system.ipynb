{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Collaborative Filtering User-Item recommendation system.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ta6Gn1SDq5tR",
        "aosXgN8Oq5tT",
        "zvaHTDOKq5tU",
        "93ILdgRiq5tc"
      ],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgB45LaXq5tN"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM314RvbrcuX",
        "outputId": "cdb92687-0f58-4e5e-89ce-20eb3a6ef439"
      },
      "source": [
        "!pip3 install pyspark\n",
        "!pip3 install lightfm\n",
        "!pip3 install apyori"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 74.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=9a92d75b405ea1c035bf7ee4c97fbd6f3700530f20190da60f3d1a83fab27f82\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 15.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=697452 sha256=827ba2b31f8b1ddfb1b0b28fb7804f8c88c2800b00cb62ec2290f133778d9e72\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n",
            "Collecting apyori\n",
            "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
            "Building wheels for collected packages: apyori\n",
            "  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5974 sha256=72f4f624ba1f1098f95a67dd1707d2720f32c6a4ad069660f4c263e44c55a4e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/f6/e1/57973c631d27efd1a2f375bd6a83b2a616c4021f24aab84080\n",
            "Successfully built apyori\n",
            "Installing collected packages: apyori\n",
            "Successfully installed apyori-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex5DhgW0q5tQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "from IPython.display import Markdown,display\n",
        "import gc\n",
        "import time\n",
        "from functools import partial\n",
        "from os import path\n",
        "from wordcloud import WordCloud\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import Word2Vec, NGram\n",
        "\n",
        "import random\n",
        "import numpy\n",
        "from scipy.sparse import coo_matrix\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import auc_score\n",
        "from apyori import apriori\n",
        "from datetime import datetime\n",
        "from itertools import combinations\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta6Gn1SDq5tR"
      },
      "source": [
        "### Reading & Merging Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK0jOWP4q5tS"
      },
      "source": [
        "# Read the data\n",
        "order_products_train = pd.read_csv('/content/drive/MyDrive/Dissertation /order_products__train.csv')\n",
        "order_products_prior = pd.read_csv('/content/drive/MyDrive/Dissertation /order_products__prior.csv')\n",
        "orders = pd.read_csv('/content/drive/MyDrive/Dissertation /orders.csv')\n",
        "products = pd.read_csv('/content/drive/MyDrive/Dissertation /products.csv')\n",
        "aisles = pd.read_csv('/content/drive/MyDrive/Dissertation /aisles.csv')\n",
        "departments = pd.read_csv('/content/drive/MyDrive/Dissertation /departments.csv')\n",
        "\n",
        "# order_products_all = pd.concat([order_products_train, order_products_prior], axis=0)\n",
        "# order_products_all = pd.merge(order_products_all, products, on='product_id', how='left')\n",
        "# order_products_all = pd.merge(order_products_all, orders, on='order_id', how='left')\n",
        "# order_products_all = pd.merge(order_products_all, aisles, on='aisle_id', how='left')\n",
        "# order_products_all = pd.merge(order_products_all, departments, on='department_id', how='left')\n",
        "\n",
        "# order_products_prior = pd.merge(order_products_prior, products, on='product_id', how='left')\n",
        "# order_products_prior = pd.merge(order_products_prior, orders, on='order_id', how='left')\n",
        "# order_products_prior = pd.merge(order_products_prior, aisles, on='aisle_id', how='left')\n",
        "# order_products_prior = pd.merge(order_products_prior, departments, on='department_id', how='left')\n",
        "\n",
        "# train_order_products = pd.merge(order_products_train, orders, on='order_id', how='left')\n",
        "# train_order_products = pd.merge(train_order_products, products, on='product_id', how='left')\n",
        "\n",
        "# order_products_train = pd.merge(order_products_train, orders, on='order_id', how='left')\n",
        "# order_products_train = pd.merge(order_products_train, products, on='product_id', how='left')\n",
        "# order_products_train = pd.merge(order_products_train, aisles, on='aisle_id', how='left')\n",
        "# order_products_train = pd.merge(order_products_train, departments, on='department_id', how='left')\n",
        "\n",
        "# # the product name is a string seperated with whitespace\n",
        "# # we want to replace all whitespace with underscore, so that each product name is actually one word with no space in btw\n",
        "# # And saving it in 'order_products_prior' table, column name 'product_name_with_no_space'\n",
        "\n",
        "# products=order_products_prior['product_name']\n",
        "# product_name_with_no_space=[]\n",
        "# for product in products:\n",
        "#     product=product.replace(\" \",\"_\")\n",
        "#     product_name_with_no_space.append(product)\n",
        "# order_products_prior['product_name_with_no_space']=product_name_with_no_space\n",
        "\n",
        "# name_list=[]\n",
        "# for p_name in order_products_prior.groupby('order_id')['product_name_with_no_space']:\n",
        "#     name_list.append(' '.join(p_name[1]))\n",
        "\n",
        "# order_id=order_products_prior.groupby('order_id')['product_name_with_no_space'].agg('count').index\n",
        "# order_products=pd.DataFrame({'order_id':order_id,'products':name_list})\n",
        "\n",
        "# order_products.head()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aosXgN8Oq5tT"
      },
      "source": [
        "### Preprocessing Aisles and Departments dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8nf5jYHq5tT"
      },
      "source": [
        "aisles=aisles[aisles['aisle'].apply(lambda x:x != 'missing' and x != 'other')]\n",
        "departments=departments[departments['department'].apply(lambda x: x != 'missing' and x != 'other')]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvaHTDOKq5tU"
      },
      "source": [
        "### Creating functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0ZpNTnqq5tV"
      },
      "source": [
        "def get_user_list(df,user_column):\n",
        "    '''\n",
        "    Creates the list of users with the user_column that comes from the inputted dataframe\n",
        "    '''\n",
        "    return np.sort(df[user_column].unique())\n",
        "\n",
        "def get_item_list(df,item_name_column):\n",
        "    '''\n",
        "    Creates a list of items, using item_name_column which contains items form the given dataframeand then returns the item list\n",
        "    '''\n",
        "    item_list=df[item_name_column].unique()\n",
        "    return item_list\n",
        "\n",
        "def get_feature_list(aisle_df,department_df,aisle_name_column,department_name_column):\n",
        "    aisle = aisle_df[aisle_name_column]\n",
        "    department = department_df[department_name_column]\n",
        "    \n",
        "    return pd.concat([aisle, department], ignore_index = True).unique()\n",
        "\n",
        "# creating user_id, item_id, and features_id\n",
        "\n",
        "def id_mappings(user_list, item_list, feature_list):\n",
        "    \"\"\"\n",
        "    \n",
        "    converting userId, itemId and featureId by mapping ids\n",
        "    \n",
        "    \"\"\"\n",
        "    user_to_index_mapping = {}\n",
        "    index_to_user_mapping = {}\n",
        "    \n",
        "    # loop through user list and assign it to either \n",
        "    # user-index mapping or index-user mapping\n",
        "    for user_index, user_id in enumerate(user_list):\n",
        "        user_to_index_mapping[user_id] = user_index\n",
        "        index_to_user_mapping[user_index] = user_id\n",
        "        \n",
        "    item_to_index_mapping = {}\n",
        "    index_to_item_mapping = {}\n",
        "    \n",
        "    # loop thorugh item list and assign it to either\n",
        "    # item-index mapping or idex-item mapping\n",
        "    for item_index, item_id in enumerate(item_list):\n",
        "        item_to_index_mapping[item_id] = item_index\n",
        "        index_to_item_mapping[item_index] = item_id\n",
        "        \n",
        "    feature_to_index_mapping = {}\n",
        "    index_to_feature_mapping = {}\n",
        "    \n",
        "    # loop thorugh feature list and assign it to either\n",
        "    # feature-index mapping or idex-feature mapping\n",
        "    for feature_index, feature_id in enumerate(feature_list):\n",
        "        feature_to_index_mapping[feature_id] = feature_index\n",
        "        index_to_feature_mapping[feature_index] = feature_id\n",
        "        \n",
        "        \n",
        "    #return the data that was mapped\n",
        "    return user_to_index_mapping, index_to_user_mapping, \\\n",
        "           item_to_index_mapping, index_to_item_mapping, \\\n",
        "           feature_to_index_mapping, index_to_feature_mapping\n",
        "\n",
        "\n",
        "def get_user_product_interaction(orders_df, order_products_train_df, order_products_test_df, products_df):\n",
        "    \n",
        "    # create user-product df by merging product and user dataset for the trainig data\n",
        "    user_to_product_train_df = orders_df[orders_df[\"eval_set\"] == \"prior\"][[\"user_id\", \"order_id\"]].\\\n",
        "    merge(order_products_train_df[[\"order_id\", \"product_id\"]]).merge(products_df[[\"product_id\", \"product_name\"]])\\\n",
        "    [[\"user_id\", \"product_name\"]].copy()\n",
        "    \n",
        "    # rate product as number purchases goes up\n",
        "    user_to_product_train_df[\"product_count\"] = 1\n",
        "    user_to_product_rating_train = user_to_product_train_df.groupby([\"user_id\", \"product_name\"], as_index = False)[\"product_count\"].sum()\n",
        "    \n",
        "    # create user-product df by merging product \n",
        "    # and user dataset for the testing data\n",
        "    user_to_product_test_df = orders_df[orders_df[\"eval_set\"] == \"train\"][[\"user_id\", \"order_id\"]].\\\n",
        "    merge(order_products_test_df[[\"order_id\", \"product_id\"]]).merge(products_df[[\"product_id\", \"product_name\"]])\\\n",
        "    [[\"user_id\", \"product_name\"]].copy()\n",
        "    \n",
        "    # giving rating as the number of product purchase count\n",
        "    # (including the previous purchase in the training data)\n",
        "    user_to_product_test_df[\"product_count\"] = 1\n",
        "    user_to_product_rating_test = user_to_product_test_df.groupby([\"user_id\", \"product_name\"], as_index = False)[\"product_count\"].sum()\n",
        "    \n",
        "    # Merge first df user-product train with test \n",
        "    user_to_product_rating_test = user_to_product_rating_test.\\\n",
        "    merge(user_to_product_rating_train.rename(columns = {\"product_count\" : \"previous_product_count\"}), how = \"left\").fillna(0)\n",
        "    user_to_product_rating_test[\"product_count\"] = user_to_product_rating_test.apply(lambda x: x[\"previous_product_count\"] + \\\n",
        "                                                                                    x[\"product_count\"], axis = 1)\n",
        "    user_to_product_rating_test.drop(columns = [\"previous_product_count\"], inplace = True)\n",
        "    \n",
        "    # return user-product rating train and test\n",
        "    return user_to_product_rating_train, user_to_product_rating_test\n",
        "\n",
        "# this function returns the interaction matrix\n",
        "def get_interaction_matrix(df, df_column_as_row, df_column_as_col, df_column_as_value, row_indexing_map, \n",
        "                          col_indexing_map):\n",
        "    \n",
        "    row = df[df_column_as_row].apply(lambda x: row_indexing_map[x]).values\n",
        "    col = df[df_column_as_col].apply(lambda x: col_indexing_map[x]).values\n",
        "    value = df[df_column_as_value].values\n",
        "    \n",
        "    return coo_matrix((value, (row, col)), shape = (len(row_indexing_map), len(col_indexing_map)))\n",
        "\n",
        "# this function returns the productFeature interaction dataframe\n",
        "def get_product_feature_interaction(product_df, aisle_df, department_df, aisle_weight = 1, department_weight = 1):\n",
        "    item_feature_df = product_df.merge(aisle_df).merge(department_df)[[\"product_name\", \"aisle\", \"department\"]]\n",
        "    \n",
        "    item_feature_df[\"product_name\"] = item_feature_df[\"product_name\"]\n",
        "    item_feature_df[\"aisle\"] = item_feature_df[\"aisle\"]\n",
        "    item_feature_df[\"department\"] = item_feature_df[\"department\"]\n",
        "    \n",
        "    # fit aisle and departments under new column named feature\n",
        "    product_aisle_df = item_feature_df[[\"product_name\", \"aisle\"]].rename(columns = {\"aisle\" : \"feature\"})\n",
        "    # adding weight to aisle feature\n",
        "    product_aisle_df[\"feature_count\"] = aisle_weight\n",
        "    product_department_df = item_feature_df[[\"product_name\", \"department\"]].rename(columns = {\"department\" : \"feature\"})\n",
        "    product_department_df[\"feature_count\"] = department_weight # adding weight to department feature\n",
        "    \n",
        "    # merge/concatinate product aisle and product department\n",
        "    # while ignoring index\n",
        "    product_feature_df = pd.concat([product_aisle_df, product_department_df], ignore_index=True)\n",
        "    \n",
        "    # This will allow the program to save memory and\n",
        "    # not crash due to the amount of data been processed\n",
        "    del item_feature_df\n",
        "    del product_aisle_df\n",
        "    del product_department_df\n",
        "    \n",
        "    # now we group the data and return the final result\n",
        "    # grouping for summing over feature_count\n",
        "    product_feature_df = product_feature_df.groupby([\"product_name\", \"feature\"], as_index = False)[\"feature_count\"].sum()\n",
        "    \n",
        "    return product_feature_df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJNHL-m0q5tZ"
      },
      "source": [
        "### Create the Lists for user,item and features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RiK6yE8q5ta",
        "outputId": "bab9644e-e749-4364-8e2c-19d4b5ab2eef"
      },
      "source": [
        "users=get_user_list(orders,'user_id')\n",
        "users"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([     1,      2,      3, ..., 206207, 206208, 206209])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-mCgOnCq5tb",
        "outputId": "68f0daf4-3bb0-4121-94c5-c43b41809c5a"
      },
      "source": [
        "items=get_item_list(products,'product_name')\n",
        "items"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Chocolate Sandwich Cookies', 'All-Seasons Salt',\n",
              "       'Robust Golden Unsweetened Oolong Tea', ..., 'Artisan Baguette',\n",
              "       'Smartblend Healthy Metabolism Dry Cat Food',\n",
              "       'Fresh Foaming Cleanser'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pIm8zLxq5tb",
        "outputId": "588f010f-56c6-43da-8d90-78670c67b0aa"
      },
      "source": [
        "features=get_feature_list(aisles,departments,'aisle','department')\n",
        "features"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['prepared soups salads', 'specialty cheeses',\n",
              "       'energy granola bars', 'instant foods',\n",
              "       'marinades meat preparation', 'packaged meat', 'bakery desserts',\n",
              "       'pasta sauce', 'kitchen supplies', 'cold flu allergy',\n",
              "       'fresh pasta', 'prepared meals', 'tofu meat alternatives',\n",
              "       'packaged seafood', 'fresh herbs', 'baking ingredients',\n",
              "       'bulk dried fruits vegetables', 'oils vinegars', 'oral hygiene',\n",
              "       'packaged cheese', 'hair care', 'popcorn jerky', 'fresh fruits',\n",
              "       'soap', 'coffee', 'beers coolers', 'red wines',\n",
              "       'honeys syrups nectars', 'latino foods', 'refrigerated',\n",
              "       'packaged produce', 'kosher foods', 'frozen meat seafood',\n",
              "       'poultry counter', 'butter', 'ice cream ice', 'frozen meals',\n",
              "       'seafood counter', 'dog food care', 'cat food care',\n",
              "       'frozen vegan vegetarian', 'buns rolls', 'eye ear care',\n",
              "       'candy chocolate', 'mint gum', 'vitamins supplements',\n",
              "       'breakfast bars pastries', 'packaged poultry',\n",
              "       'fruit vegetable snacks', 'preserved dips spreads',\n",
              "       'frozen breakfast', 'cream', 'paper goods', 'shave needs',\n",
              "       'diapers wipes', 'granola', 'frozen breads doughs',\n",
              "       'canned meals beans', 'trash bags liners', 'cookies cakes',\n",
              "       'white wines', 'grains rice dried goods', 'energy sports drinks',\n",
              "       'protein meal replacements', 'asian foods', 'fresh dips tapenades',\n",
              "       'bulk grains rice dried goods', 'soup broth bouillon', 'digestion',\n",
              "       'refrigerated pudding desserts', 'condiments', 'facial care',\n",
              "       'dish detergents', 'laundry', 'indian foods', 'soft drinks',\n",
              "       'crackers', 'frozen pizza', 'deodorants',\n",
              "       'canned jarred vegetables', 'baby accessories', 'fresh vegetables',\n",
              "       'milk', 'food storage', 'eggs', 'more household', 'spreads',\n",
              "       'salad dressing toppings', 'cocoa drink mixes', 'soy lactosefree',\n",
              "       'baby food formula', 'breakfast bakery', 'tea',\n",
              "       'canned meat seafood', 'lunch meat', 'baking supplies decor',\n",
              "       'juice nectars', 'canned fruit applesauce',\n",
              "       'air fresheners candles', 'baby bath body care',\n",
              "       'ice cream toppings', 'spices seasonings',\n",
              "       'doughs gelatins bake mixes', 'hot dogs bacon sausage',\n",
              "       'chips pretzels', 'other creams cheeses', 'skin care',\n",
              "       'pickled goods olives', 'plates bowls cups flatware', 'bread',\n",
              "       'frozen juice', 'cleaning products',\n",
              "       'water seltzer sparkling water', 'frozen produce',\n",
              "       'nuts seeds dried fruit', 'first aid', 'frozen dessert', 'yogurt',\n",
              "       'cereal', 'meat counter', 'packaged vegetables fruits', 'spirits',\n",
              "       'trail mix snack mix', 'feminine care', 'body lotions soap',\n",
              "       'tortillas flat bread', 'frozen appetizers sides',\n",
              "       'hot cereal pancake mixes', 'dry pasta', 'beauty',\n",
              "       'muscles joints pain relief', 'specialty wines champagnes',\n",
              "       'frozen', 'bakery', 'produce', 'alcohol', 'international',\n",
              "       'beverages', 'pets', 'dry goods pasta', 'bulk', 'personal care',\n",
              "       'meat seafood', 'pantry', 'breakfast', 'canned goods',\n",
              "       'dairy eggs', 'household', 'babies', 'snacks', 'deli'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ILdgRiq5tc"
      },
      "source": [
        "### Map the features to index so we can use the LightFM library that requires integer index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VlrPmiIq5tc"
      },
      "source": [
        "# Generating the mapping through LightFM algorithm and it can only read integer indexes\n",
        "user_to_index_mapping, index_to_user_mapping,item_to_index_mapping, index_to_item_mapping,feature_to_index_mapping, index_to_feature_mapping = id_mappings(users, items, features)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob1Sck1jq5td",
        "outputId": "e0a66383-12bb-46ab-d37b-8ee7afab4e94"
      },
      "source": [
        "index_to_feature_mapping"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'prepared soups salads',\n",
              " 1: 'specialty cheeses',\n",
              " 2: 'energy granola bars',\n",
              " 3: 'instant foods',\n",
              " 4: 'marinades meat preparation',\n",
              " 5: 'packaged meat',\n",
              " 6: 'bakery desserts',\n",
              " 7: 'pasta sauce',\n",
              " 8: 'kitchen supplies',\n",
              " 9: 'cold flu allergy',\n",
              " 10: 'fresh pasta',\n",
              " 11: 'prepared meals',\n",
              " 12: 'tofu meat alternatives',\n",
              " 13: 'packaged seafood',\n",
              " 14: 'fresh herbs',\n",
              " 15: 'baking ingredients',\n",
              " 16: 'bulk dried fruits vegetables',\n",
              " 17: 'oils vinegars',\n",
              " 18: 'oral hygiene',\n",
              " 19: 'packaged cheese',\n",
              " 20: 'hair care',\n",
              " 21: 'popcorn jerky',\n",
              " 22: 'fresh fruits',\n",
              " 23: 'soap',\n",
              " 24: 'coffee',\n",
              " 25: 'beers coolers',\n",
              " 26: 'red wines',\n",
              " 27: 'honeys syrups nectars',\n",
              " 28: 'latino foods',\n",
              " 29: 'refrigerated',\n",
              " 30: 'packaged produce',\n",
              " 31: 'kosher foods',\n",
              " 32: 'frozen meat seafood',\n",
              " 33: 'poultry counter',\n",
              " 34: 'butter',\n",
              " 35: 'ice cream ice',\n",
              " 36: 'frozen meals',\n",
              " 37: 'seafood counter',\n",
              " 38: 'dog food care',\n",
              " 39: 'cat food care',\n",
              " 40: 'frozen vegan vegetarian',\n",
              " 41: 'buns rolls',\n",
              " 42: 'eye ear care',\n",
              " 43: 'candy chocolate',\n",
              " 44: 'mint gum',\n",
              " 45: 'vitamins supplements',\n",
              " 46: 'breakfast bars pastries',\n",
              " 47: 'packaged poultry',\n",
              " 48: 'fruit vegetable snacks',\n",
              " 49: 'preserved dips spreads',\n",
              " 50: 'frozen breakfast',\n",
              " 51: 'cream',\n",
              " 52: 'paper goods',\n",
              " 53: 'shave needs',\n",
              " 54: 'diapers wipes',\n",
              " 55: 'granola',\n",
              " 56: 'frozen breads doughs',\n",
              " 57: 'canned meals beans',\n",
              " 58: 'trash bags liners',\n",
              " 59: 'cookies cakes',\n",
              " 60: 'white wines',\n",
              " 61: 'grains rice dried goods',\n",
              " 62: 'energy sports drinks',\n",
              " 63: 'protein meal replacements',\n",
              " 64: 'asian foods',\n",
              " 65: 'fresh dips tapenades',\n",
              " 66: 'bulk grains rice dried goods',\n",
              " 67: 'soup broth bouillon',\n",
              " 68: 'digestion',\n",
              " 69: 'refrigerated pudding desserts',\n",
              " 70: 'condiments',\n",
              " 71: 'facial care',\n",
              " 72: 'dish detergents',\n",
              " 73: 'laundry',\n",
              " 74: 'indian foods',\n",
              " 75: 'soft drinks',\n",
              " 76: 'crackers',\n",
              " 77: 'frozen pizza',\n",
              " 78: 'deodorants',\n",
              " 79: 'canned jarred vegetables',\n",
              " 80: 'baby accessories',\n",
              " 81: 'fresh vegetables',\n",
              " 82: 'milk',\n",
              " 83: 'food storage',\n",
              " 84: 'eggs',\n",
              " 85: 'more household',\n",
              " 86: 'spreads',\n",
              " 87: 'salad dressing toppings',\n",
              " 88: 'cocoa drink mixes',\n",
              " 89: 'soy lactosefree',\n",
              " 90: 'baby food formula',\n",
              " 91: 'breakfast bakery',\n",
              " 92: 'tea',\n",
              " 93: 'canned meat seafood',\n",
              " 94: 'lunch meat',\n",
              " 95: 'baking supplies decor',\n",
              " 96: 'juice nectars',\n",
              " 97: 'canned fruit applesauce',\n",
              " 98: 'air fresheners candles',\n",
              " 99: 'baby bath body care',\n",
              " 100: 'ice cream toppings',\n",
              " 101: 'spices seasonings',\n",
              " 102: 'doughs gelatins bake mixes',\n",
              " 103: 'hot dogs bacon sausage',\n",
              " 104: 'chips pretzels',\n",
              " 105: 'other creams cheeses',\n",
              " 106: 'skin care',\n",
              " 107: 'pickled goods olives',\n",
              " 108: 'plates bowls cups flatware',\n",
              " 109: 'bread',\n",
              " 110: 'frozen juice',\n",
              " 111: 'cleaning products',\n",
              " 112: 'water seltzer sparkling water',\n",
              " 113: 'frozen produce',\n",
              " 114: 'nuts seeds dried fruit',\n",
              " 115: 'first aid',\n",
              " 116: 'frozen dessert',\n",
              " 117: 'yogurt',\n",
              " 118: 'cereal',\n",
              " 119: 'meat counter',\n",
              " 120: 'packaged vegetables fruits',\n",
              " 121: 'spirits',\n",
              " 122: 'trail mix snack mix',\n",
              " 123: 'feminine care',\n",
              " 124: 'body lotions soap',\n",
              " 125: 'tortillas flat bread',\n",
              " 126: 'frozen appetizers sides',\n",
              " 127: 'hot cereal pancake mixes',\n",
              " 128: 'dry pasta',\n",
              " 129: 'beauty',\n",
              " 130: 'muscles joints pain relief',\n",
              " 131: 'specialty wines champagnes',\n",
              " 132: 'frozen',\n",
              " 133: 'bakery',\n",
              " 134: 'produce',\n",
              " 135: 'alcohol',\n",
              " 136: 'international',\n",
              " 137: 'beverages',\n",
              " 138: 'pets',\n",
              " 139: 'dry goods pasta',\n",
              " 140: 'bulk',\n",
              " 141: 'personal care',\n",
              " 142: 'meat seafood',\n",
              " 143: 'pantry',\n",
              " 144: 'breakfast',\n",
              " 145: 'canned goods',\n",
              " 146: 'dairy eggs',\n",
              " 147: 'household',\n",
              " 148: 'babies',\n",
              " 149: 'snacks',\n",
              " 150: 'deli'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6xfv3vgq5td"
      },
      "source": [
        "### How many times a product was ordered by a user in train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTbdn6B0q5td"
      },
      "source": [
        "# convert all the lists into indexes in order to read the indexes of the matrices\n",
        "user_to_product_rating_train, user_to_product_rating_test = get_user_product_interaction(orders, order_products_prior, order_products_train, products)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nOgAg4ipq5te",
        "outputId": "c9c412cd-47c2-452c-c04d-9dc4c391bd3e"
      },
      "source": [
        "# Display the user-product rating train set\n",
        "user_to_product_rating_train.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0% Greek Strained Yogurt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Aged White Cheddar Popcorn</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Bag of Organic Bananas</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Bartlett Pears</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Cinnamon Toast Crunch</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id                product_name  product_count\n",
              "0        1    0% Greek Strained Yogurt              1\n",
              "1        1  Aged White Cheddar Popcorn              2\n",
              "2        1      Bag of Organic Bananas              2\n",
              "3        1              Bartlett Pears              1\n",
              "4        1       Cinnamon Toast Crunch              3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HBPrOcj3q5te",
        "outputId": "79c5a326-ce4b-4c6f-c4fc-fed73b508982"
      },
      "source": [
        "# Display the user-product rating test set\n",
        "user_to_product_rating_test.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0% Greek Strained Yogurt</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Aged White Cheddar Popcorn</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Cinnamon Toast Crunch</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Milk Chocolate Almonds</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Organic Half &amp; Half</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id                product_name  product_count\n",
              "0        1    0% Greek Strained Yogurt            2.0\n",
              "1        1  Aged White Cheddar Popcorn            3.0\n",
              "2        1       Cinnamon Toast Crunch            4.0\n",
              "3        1      Milk Chocolate Almonds            2.0\n",
              "4        1         Organic Half & Half            3.0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk6THqPUtWwl"
      },
      "source": [
        "### Create Different matrices\n",
        "- Product-Feature matrix: this will allow to know how many products were ordered and what feature it is.\n",
        "- User-Product matrix(train&test): Relationship between user and product in train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-eQXTNBtUb7"
      },
      "source": [
        "# product feature matrix\n",
        "product_to_feature=get_product_feature_interaction(product_df=products,aisle_df=aisles,department_df=departments,aisle_weight=1,department_weight=1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ewk7eVnRyAj-",
        "outputId": "7ffac864-bc96-4ac6-a6bb-2afd202f63d2"
      },
      "source": [
        "product_to_feature.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>feature</th>\n",
              "      <th>feature_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#2 Coffee Filters</td>\n",
              "      <td>beverages</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#2 Coffee Filters</td>\n",
              "      <td>coffee</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#2 Cone White Coffee Filters</td>\n",
              "      <td>beverages</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#2 Cone White Coffee Filters</td>\n",
              "      <td>coffee</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#2 Mechanical Pencils</td>\n",
              "      <td>household</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   product_name    feature  feature_count\n",
              "0             #2 Coffee Filters  beverages              1\n",
              "1             #2 Coffee Filters     coffee              1\n",
              "2  #2 Cone White Coffee Filters  beverages              1\n",
              "3  #2 Cone White Coffee Filters     coffee              1\n",
              "4         #2 Mechanical Pencils  household              1"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd_pIoo3yC7i"
      },
      "source": [
        "# user-item matrix for training data\n",
        "user_to_product_interaction_train = get_interaction_matrix(user_to_product_rating_train, \"user_id\", \n",
        "                                                    \"product_name\", \"product_count\", user_to_index_mapping, item_to_index_mapping)\n",
        "\n",
        "# user-item matrix for testing data\n",
        "user_to_product_interaction_test = get_interaction_matrix(user_to_product_rating_test, \"user_id\", \n",
        "                                                    \"product_name\", \"product_count\", user_to_index_mapping, item_to_index_mapping)\n",
        "\n",
        "# create item-feature interaction\n",
        "product_to_feature_interaction = get_interaction_matrix(product_to_feature, \"product_name\", \"feature\",  \"feature_count\", \n",
        "                                                        item_to_index_mapping, feature_to_index_mapping)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdQFGUrkySvf"
      },
      "source": [
        "## LightFM Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdm74EUA0_Lg"
      },
      "source": [
        "#### Using pure collaborative filtering, not adding item features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nts1z5KEyMPS"
      },
      "source": [
        "# initialization of model through the warp function\n",
        "model_without_feature=LightFM(loss='warp')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrU2be3Vyi0N",
        "outputId": "9906935e-fb9c-4137-c87f-1a49a65f2dbf"
      },
      "source": [
        "# fit user-product matrix, this is only done through a pure collaborative filtering factor\n",
        "start=time.time()\n",
        "\n",
        "model_without_feature.fit(user_to_product_interaction_train,\n",
        "                          user_features=None,\n",
        "                          item_features=None,\n",
        "                          sample_weight=None,\n",
        "                          epochs=1,\n",
        "                          num_threads=4,\n",
        "                          verbose=False)\n",
        "\n",
        "end=time.time()\n",
        "print('Time taken = {0:.{1}f} seconds'.format(end-start,2))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken = 13.46 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5OEp9YozM9c",
        "outputId": "52b996ee-9e17-4ea2-9a75-203684dace07"
      },
      "source": [
        "# AUC metric score\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "auc_without_features=auc_score(model=model_without_feature,\n",
        "                               test_interactions=user_to_product_interaction_test,\n",
        "                               num_threads=4,\n",
        "                               check_intersections=False)\n",
        "end=time.time()\n",
        "print('Time taken = {0:.{1}f} seconds'.format(end-start,2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken = 195.52 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn1sRQGSzsaz",
        "outputId": "849698d1-4da9-4b28-e70e-3d73386e5d5a"
      },
      "source": [
        "print('Average AUC without adding item feature interaction = {0:{1}f}'.format(auc_without_features.mean(),2))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average AUC without adding item feature interaction = 0.947792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2YR1CxS0lUr"
      },
      "source": [
        "After modeling the data through LightFM algorithm without features we found out the Average AUC is 0.94"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCZIhtOP1QrA"
      },
      "source": [
        "#### Include item features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmDsrN9r0AjL"
      },
      "source": [
        "#model initialization\n",
        "model_with_features = LightFM(loss = \"warp\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDfTmXbU1cTU",
        "outputId": "1ad8d85d-c3e0-4a45-e29a-b5f41e308280"
      },
      "source": [
        "# fit the model but this time using a hybrid collaborative filtering and content based (product + features)\n",
        "start = time.time()\n",
        "model_with_features.fit(user_to_product_interaction_train,\n",
        "          user_features=None, \n",
        "          item_features=product_to_feature_interaction, \n",
        "          sample_weight=None, \n",
        "          epochs=1, \n",
        "          num_threads=4,\n",
        "          verbose=False)\n",
        "end = time.time()\n",
        "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken = 17.10 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKRe6bU81nB8",
        "outputId": "b3ab818b-fa74-49d9-f873-ce88241726eb"
      },
      "source": [
        "start = time.time()\n",
        "auc_with_features = auc_score(model = model_with_features, \n",
        "                        test_interactions = user_to_product_interaction_test,\n",
        "                        train_interactions = user_to_product_interaction_train, \n",
        "                        item_features = product_to_feature_interaction,\n",
        "                        num_threads = 4, check_intersections=False)\n",
        "end = time.time()\n",
        "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken = 165.81 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5kQmZbh1rPw",
        "outputId": "8f03b71b-d10b-462b-d4b8-e07cd94c5787"
      },
      "source": [
        "print(\"average AUC with adding item-feature interaction = {0:.{1}f}\".format(auc_with_features.mean(), 2))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average AUC with adding item-feature interaction = 0.80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYimPN1q2bK4"
      },
      "source": [
        "- After addind the features and training the model we found out that the AUC value is reduced to .80 when compared to the model without features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS5z6sEW2umn"
      },
      "source": [
        "## Requesting Products / Items Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3lJwoD6261p"
      },
      "source": [
        "#### We will retrain the model and will be combining train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSm3mWy51udg"
      },
      "source": [
        "def combined_train_test(train, test):\n",
        "    \"\"\"\n",
        "    \n",
        "    Combine the follwoing sets\n",
        "    training: contains previous number of order with rating by user\n",
        "    testing: contains most recent number of order with rating by user\n",
        "    \n",
        "    \"\"\"\n",
        "    # initialize and asign train dictionary\n",
        "    train_dict = {}\n",
        "    for train_row, train_col, train_data in zip(train.row, train.col, train.data):\n",
        "        train_dict[(train_row, train_col)] = train_data\n",
        "        \n",
        "    # replaces data with test data set\n",
        "    \n",
        "    for test_row, test_col, test_data in zip(test.row, test.col, test.data):\n",
        "        train_dict[(test_row, test_col)] = max(test_data, train_dict.get((test_row, test_col), 0))\n",
        "        \n",
        "    \n",
        "    # convert row, column and data elements to element array\n",
        "    row_element = []\n",
        "    col_element = []\n",
        "    data_element = []\n",
        "    for row, col in train_dict:\n",
        "        row_element.append(row)\n",
        "        col_element.append(col)\n",
        "        data_element.append(train_dict[(row, col)])\n",
        "        \n",
        "    # convert elements to np array\n",
        "    row_element = np.array(row_element)\n",
        "    col_element = np.array(col_element)\n",
        "    data_element = np.array(data_element)\n",
        "    \n",
        "    # return final data\n",
        "    return coo_matrix((data_element, (row_element, col_element)), shape = (train.shape[0], train.shape[1]))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuOvjnrA3Wzq"
      },
      "source": [
        "# combining train and test user-product interaction\n",
        "user_to_product_interaction = combined_train_test(user_to_product_interaction_train, \n",
        "                                                 user_to_product_interaction_test)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QioUAUHH3ngp",
        "outputId": "c46f059a-5753-4c82-d5bf-452ba25d9021"
      },
      "source": [
        "# now we retrain the model\n",
        "\n",
        "final_model = LightFM(loss = \"warp\")\n",
        "\n",
        "start = time.time()\n",
        "final_model.fit(user_to_product_interaction,\n",
        "          user_features=None, \n",
        "          item_features=None, \n",
        "          sample_weight=None, \n",
        "          epochs=1, \n",
        "          num_threads=4,\n",
        "          verbose=False)\n",
        "end = time.time()\n",
        "print(\"time taken = {0:.{1}f} seconds\".format(end - start, 2))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken = 13.54 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMZ960XS4U6k"
      },
      "source": [
        "### Creating a class that contains function in order to predict the recommendation based on user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66eBZOCy4PdY"
      },
      "source": [
        "class recommendation_sampling:\n",
        "    \n",
        "    def __init__(self, model, items = items, user_to_product_interaction_matrix = user_to_product_interaction, \n",
        "                user2index_map = user_to_index_mapping):\n",
        "        \n",
        "        self.user_to_product_interaction_matrix = user_to_product_interaction_matrix\n",
        "        self.model = model\n",
        "        self.items = items\n",
        "        self.user2index_map = user2index_map\n",
        "    \n",
        "    def recommendation_for_user(self, user):\n",
        "        \n",
        "        # get user index\n",
        "        \n",
        "        userindex = self.user2index_map.get(user, None)\n",
        "        \n",
        "        if userindex == None:\n",
        "            return None\n",
        "        \n",
        "        users = userindex\n",
        "        \n",
        "        # get purchased products\n",
        "        \n",
        "        known_positives = self.items[self.user_to_product_interaction_matrix.tocsr()[userindex].indices]\n",
        "        \n",
        "        # get score from predicted model\n",
        "        scores = self.model.predict(user_ids = users, item_ids = np.arange(self.user_to_product_interaction_matrix.shape[1]))\n",
        "        \n",
        "        # retrieve top scoring items\n",
        "        \n",
        "        top_items = self.items[np.argsort(-scores)]\n",
        "        \n",
        "        print(\"User \",user)\n",
        "        print(\"     Known positives:\")\n",
        "        \n",
        "        for x in known_positives[:10]:\n",
        "            print(\"                  \" ,x)\n",
        "            \n",
        "            \n",
        "        print(\"     Recommended:\")\n",
        "        \n",
        "        for x in top_items[:10]:\n",
        "            print(\"                   \",x)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnXloVp96jDP"
      },
      "source": [
        "recom=recommendation_sampling(model=final_model)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxIVoRz86qXs"
      },
      "source": [
        "#### Displaying the Recommended products for user 7 and user 20(sample)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_D3F88f6m_8",
        "outputId": "315c1991-4da7-417a-8259-714d91d0bf64"
      },
      "source": [
        "recom.recommendation_for_user(7)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User  7\n",
            "     Known positives:\n",
            "                   Snack Bags\n",
            "                   Antioxidant Infusions Brasilia Blueberry\n",
            "                   Seedless Red Grapes\n",
            "                   Large Pineapple Chunks\n",
            "                   Soft Potato Bread\n",
            "                   Apple Honeycrisp Organic\n",
            "                   Organic Red Onion\n",
            "                   Gogo Squeez Organic Apple Strawberry Applesauce on the Go\n",
            "                   Yukon Gold Potatoes 5lb Bag\n",
            "                   Mexican Finely Shredded Cheese\n",
            "     Recommended:\n",
            "                    Banana\n",
            "                    Organic Strawberries\n",
            "                    Organic Garlic\n",
            "                    Organic Hass Avocado\n",
            "                    Organic Baby Spinach\n",
            "                    Organic Avocado\n",
            "                    Bag of Organic Bananas\n",
            "                    Limes\n",
            "                    Large Lemon\n",
            "                    Organic Red Onion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFMxugQ26_9U",
        "outputId": "232e6482-09f3-40a1-cfec-8152fa12d871"
      },
      "source": [
        "recom.recommendation_for_user(20)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User  20\n",
            "     Known positives:\n",
            "                   Clementines\n",
            "                   Granny Smith Apples\n",
            "                   Apples\n",
            "                   Cheez-It Baked Snack Crackers\n",
            "                   Original Rice Krispies Treats\n",
            "                   Crunchy Oats 'n Honey Granola Bars\n",
            "                   Popcorn\n",
            "     Recommended:\n",
            "                    Soda\n",
            "                    Clementines\n",
            "                    Real Mayonnaise\n",
            "                    Roasted Pine Nut Hummus\n",
            "                    Apples\n",
            "                    Cereal\n",
            "                    Organic Simply Naked Pita Chips\n",
            "                    Sweet Kale Salad Mix\n",
            "                    Baby Cucumbers\n",
            "                    Crunchy Oats 'n Honey Granola Bars\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW-QoMJB9PU9"
      },
      "source": [
        "## Conclusion\n",
        "- From the above two tested predictions for user 7 and 20, we found out that some predicted products were bought by the customer.\n",
        "- For instance, in user 20 we can see that the model predicted a list of products, out these few products a few have be bought by the customer.\n",
        "- This concludes that atleast 1 out of 10 item are bought by the customers from the recommended list of products which are predicted by our model.\n",
        "- Moreover, our model AUC is 95%, which is a good accuracy and very accurate but the performance is very slow due to large data set which is over 8GB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDHbY6Em8s7m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}